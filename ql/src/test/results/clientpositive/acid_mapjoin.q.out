PREHOOK: query: drop table if exists acid1
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists acid1
POSTHOOK: type: DROPTABLE
PREHOOK: query: drop table if exists acid2
PREHOOK: type: DROPTABLE
POSTHOOK: query: drop table if exists acid2
POSTHOOK: type: DROPTABLE
PREHOOK: query: create table acid1 (key int, value string) clustered by (key) into 2 buckets stored as orc tblproperties ("transactional"="true")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@acid1
POSTHOOK: query: create table acid1 (key int, value string) clustered by (key) into 2 buckets stored as orc tblproperties ("transactional"="true")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@acid1
PREHOOK: query: create table acid2 (key int, value string) clustered by (key) into 2 buckets stored as orc tblproperties ("transactional"="true")
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@acid2
POSTHOOK: query: create table acid2 (key int, value string) clustered by (key) into 2 buckets stored as orc tblproperties ("transactional"="true")
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@acid2
PREHOOK: query: insert into acid1 values (1, 'a'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e'), (6, 'f'), (7, 'g'), (8, 'h')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@acid1
POSTHOOK: query: insert into acid1 values (1, 'a'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e'), (6, 'f'), (7, 'g'), (8, 'h')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@acid1
POSTHOOK: Lineage: acid1.key SCRIPT []
POSTHOOK: Lineage: acid1.value SCRIPT []
PREHOOK: query: insert into acid2 values (1,'a'),(3,'c'),(5,'e'),(7,'g')
PREHOOK: type: QUERY
PREHOOK: Input: _dummy_database@_dummy_table
PREHOOK: Output: default@acid2
POSTHOOK: query: insert into acid2 values (1,'a'),(3,'c'),(5,'e'),(7,'g')
POSTHOOK: type: QUERY
POSTHOOK: Input: _dummy_database@_dummy_table
POSTHOOK: Output: default@acid2
POSTHOOK: Lineage: acid2.key SCRIPT []
POSTHOOK: Lineage: acid2.value SCRIPT []
PREHOOK: query: alter table acid2 update statistics set('numRows'='210', 'rawDataSize'='840')
PREHOOK: type: ALTERTABLE_UPDATETABLESTATS
PREHOOK: Input: default@acid2
PREHOOK: Output: default@acid2
POSTHOOK: query: alter table acid2 update statistics set('numRows'='210', 'rawDataSize'='840')
POSTHOOK: type: ALTERTABLE_UPDATETABLESTATS
POSTHOOK: Input: default@acid2
POSTHOOK: Output: default@acid2
PREHOOK: query: alter table acid1 update statistics set('numRows'='316', 'rawDataSize'='1265')
PREHOOK: type: ALTERTABLE_UPDATETABLESTATS
PREHOOK: Input: default@acid1
PREHOOK: Output: default@acid1
POSTHOOK: query: alter table acid1 update statistics set('numRows'='316', 'rawDataSize'='1265')
POSTHOOK: type: ALTERTABLE_UPDATETABLESTATS
POSTHOOK: Input: default@acid1
POSTHOOK: Output: default@acid1
PREHOOK: query: explain
select count(*) from acid1 join acid2 on acid1.key = acid2.key
PREHOOK: type: QUERY
POSTHOOK: query: explain
select count(*) from acid1 join acid2 on acid1.key = acid2.key
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-7 depends on stages: Stage-1, Stage-4 , consists of Stage-8, Stage-9, Stage-2
  Stage-8 has a backup stage: Stage-2
  Stage-5 depends on stages: Stage-8
  Stage-3 depends on stages: Stage-2, Stage-5, Stage-6
  Stage-9 has a backup stage: Stage-2
  Stage-6 depends on stages: Stage-9
  Stage-2
  Stage-4 is a root stage
  Stage-0 depends on stages: Stage-3

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: acid1
            filterExpr: key is not null (type: boolean)
            Statistics: Num rows: 316 Data size: 1265 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 316 Data size: 1265 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 316 Data size: 1265 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: count()
                  keys: _col0 (type: int)
                  mode: hash
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 316 Data size: 1265 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: int)
                    sort order: +
                    Map-reduce partition columns: _col0 (type: int)
                    Statistics: Num rows: 316 Data size: 1265 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col1 (type: bigint)
      Execution mode: vectorized
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0)
          keys: KEY._col0 (type: int)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 158 Data size: 632 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-7
    Conditional Operator

  Stage: Stage-8
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $hdt$_0:$INTNAME1 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $hdt$_0:$INTNAME1 
          TableScan
            HashTable Sink Operator
              keys:
                0 _col0 (type: int)
                1 _col0 (type: int)

  Stage: Stage-5
    Map Reduce
      Map Operator Tree:
          TableScan
            Map Join Operator
              condition map:
                   Inner Join 0 to 1
              keys:
                0 _col0 (type: int)
                1 _col0 (type: int)
              outputColumnNames: _col1, _col3
              Statistics: Num rows: 173 Data size: 695 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: (_col1 * _col3) (type: bigint)
                outputColumnNames: _col4
                Statistics: Num rows: 173 Data size: 695 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: $sum0(_col4)
                  mode: hash
                  outputColumnNames: _col0
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
      Local Work:
        Map Reduce Local Work

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              sort order: 
              Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
              value expressions: _col0 (type: bigint)
      Execution mode: vectorized
      Reduce Operator Tree:
        Group By Operator
          aggregations: $sum0(VALUE._col0)
          mode: mergepartial
          outputColumnNames: _col0
          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-9
    Map Reduce Local Work
      Alias -> Map Local Tables:
        $hdt$_0:$INTNAME 
          Fetch Operator
            limit: -1
      Alias -> Map Local Operator Tree:
        $hdt$_0:$INTNAME 
          TableScan
            HashTable Sink Operator
              keys:
                0 _col0 (type: int)
                1 _col0 (type: int)

  Stage: Stage-6
    Map Reduce
      Map Operator Tree:
          TableScan
            Map Join Operator
              condition map:
                   Inner Join 0 to 1
              keys:
                0 _col0 (type: int)
                1 _col0 (type: int)
              outputColumnNames: _col1, _col3
              Statistics: Num rows: 173 Data size: 695 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: (_col1 * _col3) (type: bigint)
                outputColumnNames: _col4
                Statistics: Num rows: 173 Data size: 695 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: $sum0(_col4)
                  mode: hash
                  outputColumnNames: _col0
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
      Local Work:
        Map Reduce Local Work

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: int)
              sort order: +
              Map-reduce partition columns: _col0 (type: int)
              Statistics: Num rows: 158 Data size: 632 Basic stats: COMPLETE Column stats: NONE
              value expressions: _col1 (type: bigint)
          TableScan
            Reduce Output Operator
              key expressions: _col0 (type: int)
              sort order: +
              Map-reduce partition columns: _col0 (type: int)
              Statistics: Num rows: 105 Data size: 420 Basic stats: COMPLETE Column stats: NONE
              value expressions: _col1 (type: bigint)
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          keys:
            0 _col0 (type: int)
            1 _col0 (type: int)
          outputColumnNames: _col1, _col3
          Statistics: Num rows: 173 Data size: 695 Basic stats: COMPLETE Column stats: NONE
          Select Operator
            expressions: (_col1 * _col3) (type: bigint)
            outputColumnNames: _col4
            Statistics: Num rows: 173 Data size: 695 Basic stats: COMPLETE Column stats: NONE
            Group By Operator
              aggregations: $sum0(_col4)
              mode: hash
              outputColumnNames: _col0
              Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-4
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: acid2
            filterExpr: key is not null (type: boolean)
            Statistics: Num rows: 210 Data size: 840 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: key is not null (type: boolean)
              Statistics: Num rows: 210 Data size: 840 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 210 Data size: 840 Basic stats: COMPLETE Column stats: NONE
                Group By Operator
                  aggregations: count()
                  keys: _col0 (type: int)
                  mode: hash
                  outputColumnNames: _col0, _col1
                  Statistics: Num rows: 210 Data size: 840 Basic stats: COMPLETE Column stats: NONE
                  Reduce Output Operator
                    key expressions: _col0 (type: int)
                    sort order: +
                    Map-reduce partition columns: _col0 (type: int)
                    Statistics: Num rows: 210 Data size: 840 Basic stats: COMPLETE Column stats: NONE
                    value expressions: _col1 (type: bigint)
      Execution mode: vectorized
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0)
          keys: KEY._col0 (type: int)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 105 Data size: 420 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: select count(*) from acid1 join acid2 on acid1.key = acid2.key
PREHOOK: type: QUERY
PREHOOK: Input: default@acid1
PREHOOK: Input: default@acid2
#### A masked pattern was here ####
POSTHOOK: query: select count(*) from acid1 join acid2 on acid1.key = acid2.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@acid1
POSTHOOK: Input: default@acid2
#### A masked pattern was here ####
4
PREHOOK: query: drop table acid1
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@acid1
PREHOOK: Output: default@acid1
POSTHOOK: query: drop table acid1
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@acid1
POSTHOOK: Output: default@acid1
PREHOOK: query: drop table acid2
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@acid2
PREHOOK: Output: default@acid2
POSTHOOK: query: drop table acid2
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@acid2
POSTHOOK: Output: default@acid2
