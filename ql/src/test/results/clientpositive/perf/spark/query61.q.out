Warning: Map Join MAPJOIN[105][bigTable=?] in task 'Stage-1:MAPRED' is a cross product
PREHOOK: query: explain
select  promotions,total,cast(promotions as decimal(15,4))/cast(total as decimal(15,4))*100
from
  (select sum(ss_ext_sales_price) promotions
   from  store_sales
        ,store
        ,promotion
        ,date_dim
        ,customer
        ,customer_address 
        ,item
   where ss_sold_date_sk = d_date_sk
   and   ss_store_sk = s_store_sk
   and   ss_promo_sk = p_promo_sk
   and   ss_customer_sk= c_customer_sk
   and   ca_address_sk = c_current_addr_sk
   and   ss_item_sk = i_item_sk 
   and   ca_gmt_offset = -7
   and   i_category = 'Electronics'
   and   (p_channel_dmail = 'Y' or p_channel_email = 'Y' or p_channel_tv = 'Y')
   and   s_gmt_offset = -7
   and   d_year = 1999
   and   d_moy  = 11) promotional_sales,
  (select sum(ss_ext_sales_price) total
   from  store_sales
        ,store
        ,date_dim
        ,customer
        ,customer_address
        ,item
   where ss_sold_date_sk = d_date_sk
   and   ss_store_sk = s_store_sk
   and   ss_customer_sk= c_customer_sk
   and   ca_address_sk = c_current_addr_sk
   and   ss_item_sk = i_item_sk
   and   ca_gmt_offset = -7
   and   i_category = 'Electronics'
   and   s_gmt_offset = -7
   and   d_year = 1999
   and   d_moy  = 11) all_sales
order by promotions, total
limit 100
PREHOOK: type: QUERY
POSTHOOK: query: explain
select  promotions,total,cast(promotions as decimal(15,4))/cast(total as decimal(15,4))*100
from
  (select sum(ss_ext_sales_price) promotions
   from  store_sales
        ,store
        ,promotion
        ,date_dim
        ,customer
        ,customer_address 
        ,item
   where ss_sold_date_sk = d_date_sk
   and   ss_store_sk = s_store_sk
   and   ss_promo_sk = p_promo_sk
   and   ss_customer_sk= c_customer_sk
   and   ca_address_sk = c_current_addr_sk
   and   ss_item_sk = i_item_sk 
   and   ca_gmt_offset = -7
   and   i_category = 'Electronics'
   and   (p_channel_dmail = 'Y' or p_channel_email = 'Y' or p_channel_tv = 'Y')
   and   s_gmt_offset = -7
   and   d_year = 1999
   and   d_moy  = 11) promotional_sales,
  (select sum(ss_ext_sales_price) total
   from  store_sales
        ,store
        ,date_dim
        ,customer
        ,customer_address
        ,item
   where ss_sold_date_sk = d_date_sk
   and   ss_store_sk = s_store_sk
   and   ss_customer_sk= c_customer_sk
   and   ca_address_sk = c_current_addr_sk
   and   ss_item_sk = i_item_sk
   and   ca_gmt_offset = -7
   and   i_category = 'Electronics'
   and   s_gmt_offset = -7
   and   d_year = 1999
   and   d_moy  = 11) all_sales
order by promotions, total
limit 100
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-5 is a root stage
  Stage-4 depends on stages: Stage-5
  Stage-3 depends on stages: Stage-4
  Stage-2 depends on stages: Stage-3
  Stage-9 depends on stages: Stage-2
  Stage-8 depends on stages: Stage-9
  Stage-7 depends on stages: Stage-8
  Stage-6 depends on stages: Stage-7
  Stage-1 depends on stages: Stage-6
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-5
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 16 
            Map Operator Tree:
                TableScan
                  alias: date_dim
                  filterExpr: ((d_year = 1999) and (d_moy = 11) and d_date_sk is not null) (type: boolean)
                  Statistics: Num rows: 73049 Data size: 876588 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((d_moy = 11) and (d_year = 1999) and d_date_sk is not null) (type: boolean)
                    Statistics: Num rows: 50 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: d_date_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 50 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                      Spark HashTable Sink Operator
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work
        Map 17 
            Map Operator Tree:
                TableScan
                  alias: item
                  filterExpr: ((i_category = 'Electronics') and i_item_sk is not null) (type: boolean)
                  Statistics: Num rows: 462000 Data size: 43428000 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((i_category = 'Electronics') and i_item_sk is not null) (type: boolean)
                    Statistics: Num rows: 46200 Data size: 4342800 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: i_item_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 46200 Data size: 4573800 Basic stats: COMPLETE Column stats: COMPLETE
                      Spark HashTable Sink Operator
                        keys:
                          0 _col1 (type: int)
                          1 _col0 (type: int)
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work

  Stage: Stage-4
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 15 
            Map Operator Tree:
                TableScan
                  alias: store_sales
                  filterExpr: (ss_store_sk is not null and ss_sold_date_sk is not null and ss_customer_sk is not null and ss_item_sk is not null) (type: boolean)
                  Statistics: Num rows: 575995635 Data size: 70513520748 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (ss_customer_sk is not null and ss_item_sk is not null and ss_sold_date_sk is not null and ss_store_sk is not null) (type: boolean)
                    Statistics: Num rows: 501694138 Data size: 61417514116 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: ss_sold_date_sk (type: int), ss_item_sk (type: int), ss_customer_sk (type: int), ss_store_sk (type: int), ss_ext_sales_price (type: decimal(7,2))
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4
                      Statistics: Num rows: 501694138 Data size: 61417514116 Basic stats: COMPLETE Column stats: COMPLETE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
                        outputColumnNames: _col1, _col2, _col3, _col4
                        input vertices:
                          1 Map 16
                        Statistics: Num rows: 13737330 Data size: 54949440 Basic stats: COMPLETE Column stats: COMPLETE
                        Map Join Operator
                          condition map:
                               Inner Join 0 to 1
                          keys:
                            0 _col1 (type: int)
                            1 _col0 (type: int)
                          outputColumnNames: _col2, _col3, _col4
                          input vertices:
                            1 Map 17
                          Statistics: Num rows: 13222427 Data size: 120 Basic stats: COMPLETE Column stats: COMPLETE
                          Spark HashTable Sink Operator
                            keys:
                              0 _col3 (type: int)
                              1 _col0 (type: int)
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work

  Stage: Stage-3
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 18 
            Map Operator Tree:
                TableScan
                  alias: store
                  filterExpr: ((s_gmt_offset = -7) and s_store_sk is not null) (type: boolean)
                  Statistics: Num rows: 1704 Data size: 196768 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((s_gmt_offset = -7) and s_store_sk is not null) (type: boolean)
                    Statistics: Num rows: 341 Data size: 39444 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: s_store_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 341 Data size: 39556 Basic stats: COMPLETE Column stats: COMPLETE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col3 (type: int)
                          1 _col0 (type: int)
                        outputColumnNames: _col2, _col4
                        input vertices:
                          0 Map 15
                        Statistics: Num rows: 2646038 Data size: 116 Basic stats: COMPLETE Column stats: COMPLETE
                        Spark HashTable Sink Operator
                          keys:
                            0 _col0 (type: int)
                            1 _col2 (type: int)
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work

  Stage: Stage-2
    Spark
      Edges:
        Reducer 12 <- Map 11 (PARTITION-LEVEL SORT, 13), Map 14 (PARTITION-LEVEL SORT, 13)
        Reducer 13 <- Reducer 12 (GROUP, 1)
#### A masked pattern was here ####
      Vertices:
        Map 11 
            Map Operator Tree:
                TableScan
                  alias: customer
                  filterExpr: (c_customer_sk is not null and c_current_addr_sk is not null) (type: boolean)
                  Statistics: Num rows: 80000000 Data size: 640000000 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (c_current_addr_sk is not null and c_customer_sk is not null) (type: boolean)
                    Statistics: Num rows: 80000000 Data size: 640000000 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: c_customer_sk (type: int), c_current_addr_sk (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 80000000 Data size: 640000000 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col1 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col1 (type: int)
                        Statistics: Num rows: 80000000 Data size: 640000000 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: int)
            Execution mode: vectorized
        Map 14 
            Map Operator Tree:
                TableScan
                  alias: customer_address
                  filterExpr: ((ca_gmt_offset = -7) and ca_address_sk is not null) (type: boolean)
                  Statistics: Num rows: 40000000 Data size: 4505468064 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((ca_gmt_offset = -7) and ca_address_sk is not null) (type: boolean)
                    Statistics: Num rows: 8000000 Data size: 901093680 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: ca_address_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 8000000 Data size: 928000000 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 8000000 Data size: 928000000 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized
        Reducer 12 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 16000001 Data size: 64000004 Basic stats: COMPLETE Column stats: COMPLETE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  keys:
                    0 _col0 (type: int)
                    1 _col2 (type: int)
                  outputColumnNames: _col8
                  input vertices:
                    1 Map 18
                  Statistics: Num rows: 529208 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: sum(_col8)
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: decimal(17,2))
        Reducer 13 
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                Spark HashTable Sink Operator
                  keys:
                    0 
                    1 

  Stage: Stage-9
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 7 
            Map Operator Tree:
                TableScan
                  alias: date_dim
                  filterExpr: ((d_year = 1999) and (d_moy = 11) and d_date_sk is not null) (type: boolean)
                  Statistics: Num rows: 73049 Data size: 876588 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((d_moy = 11) and (d_year = 1999) and d_date_sk is not null) (type: boolean)
                    Statistics: Num rows: 50 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: d_date_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 50 Data size: 600 Basic stats: COMPLETE Column stats: COMPLETE
                      Spark HashTable Sink Operator
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work
        Map 8 
            Map Operator Tree:
                TableScan
                  alias: item
                  filterExpr: ((i_category = 'Electronics') and i_item_sk is not null) (type: boolean)
                  Statistics: Num rows: 462000 Data size: 43428000 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((i_category = 'Electronics') and i_item_sk is not null) (type: boolean)
                    Statistics: Num rows: 46200 Data size: 4342800 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: i_item_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 46200 Data size: 4573800 Basic stats: COMPLETE Column stats: COMPLETE
                      Spark HashTable Sink Operator
                        keys:
                          0 _col1 (type: int)
                          1 _col0 (type: int)
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work

  Stage: Stage-8
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 6 
            Map Operator Tree:
                TableScan
                  alias: store_sales
                  filterExpr: (ss_store_sk is not null and ss_promo_sk is not null and ss_sold_date_sk is not null and ss_customer_sk is not null and ss_item_sk is not null) (type: boolean)
                  Statistics: Num rows: 575995635 Data size: 72713838164 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (ss_customer_sk is not null and ss_item_sk is not null and ss_promo_sk is not null and ss_sold_date_sk is not null and ss_store_sk is not null) (type: boolean)
                    Statistics: Num rows: 479120970 Data size: 60484355364 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: ss_sold_date_sk (type: int), ss_item_sk (type: int), ss_customer_sk (type: int), ss_store_sk (type: int), ss_promo_sk (type: int), ss_ext_sales_price (type: decimal(7,2))
                      outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5
                      Statistics: Num rows: 479120970 Data size: 60484355364 Basic stats: COMPLETE Column stats: COMPLETE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col0 (type: int)
                          1 _col0 (type: int)
                        outputColumnNames: _col1, _col2, _col3, _col4, _col5
                        input vertices:
                          1 Map 7
                        Statistics: Num rows: 13119234 Data size: 52477060 Basic stats: COMPLETE Column stats: COMPLETE
                        Map Join Operator
                          condition map:
                               Inner Join 0 to 1
                          keys:
                            0 _col1 (type: int)
                            1 _col0 (type: int)
                          outputColumnNames: _col2, _col3, _col4, _col5
                          input vertices:
                            1 Map 8
                          Statistics: Num rows: 12627499 Data size: 124 Basic stats: COMPLETE Column stats: COMPLETE
                          Spark HashTable Sink Operator
                            keys:
                              0 _col3 (type: int)
                              1 _col0 (type: int)
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work

  Stage: Stage-7
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 9 
            Map Operator Tree:
                TableScan
                  alias: store
                  filterExpr: ((s_gmt_offset = -7) and s_store_sk is not null) (type: boolean)
                  Statistics: Num rows: 1704 Data size: 196768 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((s_gmt_offset = -7) and s_store_sk is not null) (type: boolean)
                    Statistics: Num rows: 341 Data size: 39444 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: s_store_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 341 Data size: 39556 Basic stats: COMPLETE Column stats: COMPLETE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col3 (type: int)
                          1 _col0 (type: int)
                        outputColumnNames: _col2, _col4, _col5
                        input vertices:
                          0 Map 6
                        Statistics: Num rows: 2526982 Data size: 120 Basic stats: COMPLETE Column stats: COMPLETE
                        Spark HashTable Sink Operator
                          keys:
                            0 _col4 (type: int)
                            1 _col0 (type: int)
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work

  Stage: Stage-6
    Spark
#### A masked pattern was here ####
      Vertices:
        Map 10 
            Map Operator Tree:
                TableScan
                  alias: promotion
                  filterExpr: (((p_channel_dmail = 'Y') or (p_channel_email = 'Y') or (p_channel_tv = 'Y')) and p_promo_sk is not null) (type: boolean)
                  Statistics: Num rows: 2300 Data size: 595700 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (((p_channel_dmail = 'Y') or (p_channel_email = 'Y') or (p_channel_tv = 'Y')) and p_promo_sk is not null) (type: boolean)
                    Statistics: Num rows: 2300 Data size: 595700 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: p_promo_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 2300 Data size: 595700 Basic stats: COMPLETE Column stats: COMPLETE
                      Map Join Operator
                        condition map:
                             Inner Join 0 to 1
                        keys:
                          0 _col4 (type: int)
                          1 _col0 (type: int)
                        outputColumnNames: _col2, _col5
                        input vertices:
                          0 Map 9
                        Statistics: Num rows: 2526982 Data size: 116 Basic stats: COMPLETE Column stats: COMPLETE
                        Spark HashTable Sink Operator
                          keys:
                            0 _col0 (type: int)
                            1 _col2 (type: int)
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work

  Stage: Stage-1
    Spark
      Edges:
        Reducer 2 <- Map 1 (PARTITION-LEVEL SORT, 13), Map 5 (PARTITION-LEVEL SORT, 13)
        Reducer 3 <- Reducer 2 (GROUP, 1)
        Reducer 4 <- Reducer 3 (SORT, 1)
#### A masked pattern was here ####
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: customer
                  filterExpr: (c_customer_sk is not null and c_current_addr_sk is not null) (type: boolean)
                  Statistics: Num rows: 80000000 Data size: 640000000 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: (c_current_addr_sk is not null and c_customer_sk is not null) (type: boolean)
                    Statistics: Num rows: 80000000 Data size: 640000000 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: c_customer_sk (type: int), c_current_addr_sk (type: int)
                      outputColumnNames: _col0, _col1
                      Statistics: Num rows: 80000000 Data size: 640000000 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col1 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col1 (type: int)
                        Statistics: Num rows: 80000000 Data size: 640000000 Basic stats: COMPLETE Column stats: COMPLETE
                        value expressions: _col0 (type: int)
            Execution mode: vectorized
        Map 5 
            Map Operator Tree:
                TableScan
                  alias: customer_address
                  filterExpr: ((ca_gmt_offset = -7) and ca_address_sk is not null) (type: boolean)
                  Statistics: Num rows: 40000000 Data size: 4505468064 Basic stats: COMPLETE Column stats: COMPLETE
                  Filter Operator
                    predicate: ((ca_gmt_offset = -7) and ca_address_sk is not null) (type: boolean)
                    Statistics: Num rows: 8000000 Data size: 901093680 Basic stats: COMPLETE Column stats: COMPLETE
                    Select Operator
                      expressions: ca_address_sk (type: int)
                      outputColumnNames: _col0
                      Statistics: Num rows: 8000000 Data size: 928000000 Basic stats: COMPLETE Column stats: COMPLETE
                      Reduce Output Operator
                        key expressions: _col0 (type: int)
                        sort order: +
                        Map-reduce partition columns: _col0 (type: int)
                        Statistics: Num rows: 8000000 Data size: 928000000 Basic stats: COMPLETE Column stats: COMPLETE
            Execution mode: vectorized
        Reducer 2 
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Join Operator
                condition map:
                     Inner Join 0 to 1
                keys:
                  0 _col1 (type: int)
                  1 _col0 (type: int)
                outputColumnNames: _col0
                Statistics: Num rows: 16000001 Data size: 64000004 Basic stats: COMPLETE Column stats: COMPLETE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  keys:
                    0 _col0 (type: int)
                    1 _col2 (type: int)
                  outputColumnNames: _col9
                  input vertices:
                    1 Map 10
                  Statistics: Num rows: 505397 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                  Group By Operator
                    aggregations: sum(_col9)
                    mode: hash
                    outputColumnNames: _col0
                    Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      sort order: 
                      Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                      value expressions: _col0 (type: decimal(17,2))
        Reducer 3 
            Execution mode: vectorized
            Local Work:
              Map Reduce Local Work
            Reduce Operator Tree:
              Group By Operator
                aggregations: sum(VALUE._col0)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 112 Basic stats: COMPLETE Column stats: COMPLETE
                Map Join Operator
                  condition map:
                       Inner Join 0 to 1
                  keys:
                    0 
                    1 
                  outputColumnNames: _col0, _col1
                  input vertices:
                    1 Reducer 13
                  Statistics: Num rows: 1 Data size: 224 Basic stats: COMPLETE Column stats: COMPLETE
                  Select Operator
                    expressions: _col0 (type: decimal(17,2)), _col1 (type: decimal(17,2)), ((CAST( _col0 AS decimal(15,4)) / CAST( _col1 AS decimal(15,4))) * 100) (type: decimal(38,19))
                    outputColumnNames: _col0, _col1, _col2
                    Statistics: Num rows: 1 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                    Reduce Output Operator
                      key expressions: _col0 (type: decimal(17,2)), _col1 (type: decimal(17,2))
                      sort order: ++
                      Statistics: Num rows: 1 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                      TopN Hash Memory Usage: 0.1
                      value expressions: _col2 (type: decimal(38,19))
        Reducer 4 
            Execution mode: vectorized
            Reduce Operator Tree:
              Select Operator
                expressions: KEY.reducesinkkey0 (type: decimal(17,2)), KEY.reducesinkkey1 (type: decimal(17,2)), VALUE._col0 (type: decimal(38,19))
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 1 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                Limit
                  Number of rows: 100
                  Statistics: Num rows: 1 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 336 Basic stats: COMPLETE Column stats: COMPLETE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 100
      Processor Tree:
        ListSink

